---
title: "DADA2 sample processing for *A. cervicornis* microplastics project"
date: "*Last run on `r format(Sys.time(), '%d %B %Y')`*"
output: 
  html_document:
  theme: flatly
toc: yes
toc_depth: 3
toc_float: yes
---

```{r set some defaults, echo = FALSE}

library("knitr")
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
pdf.options(useDingbats = FALSE)

```

```{r install dada2, eval = FALSE, include = FALSE}

## Downloading DADA2 following instructions found here:
# https://benjjneb.github.io/dada2/dada-installation.html

install.packages("devtools")
library("devtools")
devtools::install_github("benjjneb/dada2", ref="v1.18") # change the ref argument to get other versions

```

```{r load packages, echo = FALSE}

library(dada2) # I have version 1.18.0 downloaded on the SCC for this
library(tidyverse)

```

<br/>

I am largely following the [DADA2](https://www.bioconductor.org/packages/release/bioc/manuals/dada2/man/dada2.pdf) tutorial by Benjamin Callahan that can be found [here](https://benjjneb.github.io/dada2/tutorial.html). 


## Inspecting the data {.tabset}

```{r set path to 16S samples}

## the directory containing the fastq files after unzipping.
path_16S <- "/projectnb/davieslab/bove/acer_MP/final_samples/16S_29Jun22" 

# looks good! need to specify only using the microplastic samples
# list.files(path_16S)

```

```{r extract fastq files and sample names}

# Forward and reverse fastq filenames have format: SAMPLENAME_R1.fastq and SAMPLENAME_R2.fastq
fnFs <- sort(list.files(path_16S, pattern = "_R1.fastq", full.names = TRUE))
fnRs <- sort(list.files(path_16S, pattern = "_R2.fastq", full.names = TRUE))

# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sample_names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)

```

### Check samples to use

```{r select only microplastic samples}

## read in the meta data from the samples
meta <- read.csv("Data/Acerv_MP_Metadata.csv")


# filter the sample name list to select neg controls and microplastic samples only
sample_names <- sample_names[sample_names %in% meta$sampleID]
sample_names


# filter the forward sequences for microplastics only
fnFs <- fnFs %>% 
  str_detect("/A|/B|/C|G5|G6", negate = FALSE) %>%
  keep(fnFs, .)

# filter the reverse sequences for microplastics only
fnRs <- fnRs %>% 
  str_detect("/A|/B|/C|G5|G6", negate = FALSE) %>%
  keep(fnRs, .)

```

<br/>
<br/>


### View example quality plots

Viewing the quality of 2 of the forward samples
```{r firward quality plots}

## This first sample is giving us the error:
# Error: BiocParallel errors
#   1 remote errors, element index: 1
#   0 unevaluated and other errors
#   first remote error: 'x' contains missing values

## To fix this, I am going to go back and add '--minimum-length 1' to the 
# cutadapt step to discard processed reads that are shorter than LENGTH.

## Plot 2 samples for examples:
plotQualityProfile(fnFs[2:3])


## Saving the quality profiles of all (except sample A1) to view later if necessary
Fs_qualityPlot <- plotQualityProfile(fnFs[-1])

pdf(file = "Figures/Forward_qualityPlots.pdf", width = 18, height = 14)
Fs_qualityPlot
dev.off()

```


Viewing the quality of the same 2 of the reverse samples
```{r reverse quality plots}

## Plot 2 reverse samples for examples:
plotQualityProfile(fnRs[2:3])

## Saving the quality profiles of all to view later if necessary
Rs_qualityPlot <- plotQualityProfile(fnRs)

pdf(file = "Figures/Reverse_qualityPlots.pdf", width = 18, height = 14)
Rs_qualityPlot
dev.off()

```

<br/>
<br/>


## Filter and trim samples {.tabset}

### Perform the filtering

```{r}

# Place filtered files in filtered/ subdirectory
filtFs <- file.path(path_16S, "filtered", paste0(sample_names, "_filt_F.fastq.gz"))
filtRs <- file.path(path_16S, "filtered", paste0(sample_names, "_filt_R.fastq.gz"))

names(filtFs) <- sample_names
names(filtRs) <- sample_names

```

```{r}

out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs,
                     truncLen = c(220, 210), # cut for the forward and reverse files
                     maxN = 0, # DADA2 requires no Ns
                     maxEE = c(1, 1), # reads with higher than maxEE "expected errors" will be discarded
                     truncQ = 2, # Truncate reads at the first instance of a quality score less than or equal to truncQ
                     rm.phix = TRUE, # If TRUE, discard reads that match against the phiX genome (kinda control bacteria)
                     compress = TRUE, #  Whether the output fastq file should be gzip com- pressed.
                     multithread = TRUE) # On Windows set multithread = FALSE
head(out)

```


<br/>
<br/>

### Check the filtering

Viewing the quality of the same 2 of the forward samples post filtering and trimming
```{r forward quality plots post filter trim}

## plot the filtered forward samples
plotQualityProfile(filtFs[2:3])


```

```{r save forward quality plots post filter trim, eval=FALSE, include=FALSE}

## save the filtered forward quality plots
pdf(file = "Figures/Forward_filt_qualityPlots.pdf", width = 18, height = 14)
plotQualityProfile(filtFs)
dev.off()

```

Viewing the quality of the same 2 of the reverse samples post filtering and trimming
```{r reverse quality plots post filter trim}

## plot the filtered reverse samples
plotQualityProfile(filtRs[2:3])

```

```{r save reverse quality plots post filter trim, eval=FALSE, include=FALSE}

## save the filtered reverse quality plots
pdf(file = "Figures/Reverse_filt_qualityPlots.pdf", width = 18, height = 14)
plotQualityProfile(filtRs)
dev.off()

```

<br/>
<br/>


### Learn Error Rates

```{r}

errF <- learnErrors(filtFs, multithread = TRUE)
plotErrors(errF, nominalQ = TRUE)


errR <- learnErrors(filtRs, multithread = TRUE)
plotErrors(errR, nominalQ = TRUE)


dadaFs <- dada(filtFs, err=errF, multithread=TRUE)
dadaFs[[1]]

dadaRs <- dada(filtRs, err=errR, multithread=TRUE)
dadaRs[[1]]

```

<br/>
<br/>


## Merge paired reads

```{r}

### Dereplicate reads

#Dereplication combines all identical sequencing reads into into “unique sequences” with a corresponding “abundance”: the number of reads with that unique sequence. 
#Dereplication substantially reduces computation time by eliminating redundant comparisons.
#DADA2 retains a summary of the quality information associated with each unique sequence. The consensus quality profile of a unique sequence is the average of the positional qualities from the dereplicated reads. These quality profiles inform the error model of the subsequent denoising step, significantly increasing DADA2’s accuracy.
derepFs <- derepFastq(filtFs, verbose=TRUE)
derepRs <- derepFastq(filtRs, verbose=TRUE)
# Name the derep-class objects by the sample names
names(derepFs) <- sample_names
names(derepRs) <- sample_names

dadaFs <- dada(derepFs, err=errF, multithread=TRUE)
dadaRs <- dada(derepRs, err=errR, multithread=TRUE)

#now, look at the dada class objects by sample
#will tell how many 'real' variants in unique input seqs
#By default, the dada function processes each sample independently, but pooled processing is available with pool=TRUE and that may give better results for low sampling depths at the cost of increased computation time. See our discussion about pooling samples for sample inference. 
dadaFs[[1]]
dadaRs[[1]]



#To further cull spurious sequence variants
#Merge the denoised forward and reverse reads
#Paired reads that do not exactly overlap are removed

mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers[[1]])

summary((mergers[[1]]))

#We now have a data.frame for each sample with the merged $sequence, its $abundance, and the indices of the merged $forward and $reverse denoised sequences. Paired reads that did not exactly overlap were removed by mergePairs.

seqtab <- makeSequenceTable(mergers)

dim(seqtab)

# Inspect distribution of sequence lengths
table(nchar(getSequences(seqtab)))

#saveRDS(seqtab,file="fl16s.seqtab.rds")

plot(table(nchar(getSequences(seqtab)))) #real variants appear to be right in that 244-264 window
### note: I've done this part previously to look at the peak before proceeding with desired length trimming below

#The sequence table is a matrix with rows corresponding to (and named by) the samples, and 
#columns corresponding to (and named by) the sequence variants. 
#Sequences that are much longer or shorter than expected may be the result of non-specific priming, and may be worth removing

seqtab2 <- seqtab[,nchar(colnames(seqtab)) %in% seq(244,264)] #again, being fairly conservative wrt length

#The core dada method removes substitution and indel errors, but chimeras remain. 
#Fortunately, the accuracy of the sequences after denoising makes identifying chimeras easier 
#than it is when dealing with fuzzy OTUs: all sequences which can be exactly reconstructed as 
#a bimera (two-parent chimera) from more abundant sequences.

seqtab.nochim <- removeBimeraDenovo(seqtab2, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtab.nochim)
#Identified 1930 bimeras out of 77085 input sequences.

sum(seqtab.nochim)/sum(seqtab2)
#
#The fraction of chimeras varies based on factors including experimental procedures and sample complexity, 
#but can be substantial. 

# Track Read Stats #
 
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(mergers, getN), rowSums(seqtab2), rowSums(seqtab.nochim))
colnames(track) <- c("input", "filtered", "denoised", "merged", "tabled", "nonchim")
rownames(track) <- sample_names
head(track)
tail(track)

write.csv(track,file="Data/fl16s_readstats.csv",row.names=TRUE,quote=FALSE)
saveRDS(seqtab.nochim,file="Data/fl16s_seqtab_nochim.RDS")





seqtab.nochim <- readRDS("Data/fl16s_seqtab_nochim.RDS")

ncol(seqtab.nochim)
#75,430 raw ASVs

sum(colSums(seqtab.nochim))
#16793981 (16 million reads)
#0.0005% = 84 reads

seq.raw.keep <- which(colSums(seqtab.nochim)*100/(sum(colSums(seqtab.nochim))) > 0.0005)
seq.trim <- seqtab.nochim[,seq.raw.keep]
ncol(seq.trim)
#12,836 ASVs remain

saveRDS(seq.trim, file="fl16s_seqtab_trim0005.rds")

```




## Session Information

All code was written by [Colleen B. Bove](https://colleenbove.science), feel free to contact with questions.

Session information from the last run date on `r format(Sys.time(), '%d %B %Y')`:

```{r print session info}

sessionInfo()

```
